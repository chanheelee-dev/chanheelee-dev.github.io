# 마케팅 Life Time Value (LTV) 예측 프로젝트

진행 기간: 2021.01 ~ 2024.03

## 프로젝트 소개

효율적인 마케팅 예산 집행을 위해 캠페인 별 평생 가치(LTV)를 예측하는 프로젝트.

## 문제 상황

- 마케팅은 '캠페인'이라는 단위로 예산을 집행함. 캠페인 별로 초반 3-7 일 동안의 퍼포먼스 데이터를 측정해, 장기적으로 **'가망이 있는'** 캠페인 위주로 예산을 빠르게 재집행함으로써 효율적으로 마케팅을 지속하는 것이 주 목표.
- 초반 퍼포먼스로만 캠페인을 판단하는 것은 마케터 개인의 경험과 주관에 의존할 수 밖에 없기 때문에 안정적인 지표가 필요함.
- 퍼포먼스 지표로 주로 활용하는 것은 광고 비용 대비 회수율(ROAS)이지만, 이 지표는 자연 유입된 유저를 대상으로 계산할 수 없음. LTV 값을 통해 ROAS를 계산하는 것도 가능하기 때문에 결국 LTV를 예측하는 것이 더 보편적으로 활용 가능.

## 프로젝트 목표

- 마케터가 캠페인의 장기 성과를 예측하는 데 도움이 되는 데이터를 제공한다. 이를 위해 초기 데이터를 활용해 광고 비용 대비 회수율(ROAS)이나 평생 가치(LTV)를 예측한다.

## 프로젝트 변천사

LTV 프로젝트는 제가 이어받기 전인 2017년부터 연구가 시작돼서 장장 7년이 넘게 지속된 프로젝트인만큼, 프로젝트 나름의 역사를 가지고 있습니다. 제가 프로젝트에 참여하기 시작한 2021년부터, 프로젝트가 마무리 된 2024년까지의 변천사를 큼직한 변화를 기준으로 '스테이지'로 구분해 설명해보겠습니다.

| stage | 기간 | 한 줄 요약 | 모델링 | 서빙 방식 | 데이터/훈련/서빙 파이프라인 |
| --- | --- | --- | --- | --- | --- |
| 1 | 2021 | 기존 서비스 유지보수 | Bayesian (MCMC) | dashboard / jupyter notebook | 서빙: airflow |
| 2 | 2022 | 모델 성능 개선 | MCMC + linear regression | dashboard / jupyter notebook | 서빙: airflow |
| 3 | 2023 상반기 | UX + 속도 개선 | 위와 동일 | AWS Sagemaker + Dash web | 데이터: AWS lambda, 서빙: AWS Sagemaker + lambda |
| 4 | 2023 하반기 | 모델링 방법론 변경 | Deep learning (MLP, TiDE) | dashboard | 데이터: databricks, 훈련: mlflow, 서빙: databricks |
| 5 | 2024 | 초기 수준의 MLOps 구축 | classical ML | mlflow model registry | 데이터: databricks, 훈련: mlflow, 서빙: mlflow |

### Stage 1: LTV 초기 모델

LTV 예측 프로젝트는 제가 입사한 2021년 이전부터 오랫동안 연구가 이어진 오래된 프로젝트로, 이미 LTV 예측값을 통해 마케터가 캠페인의 성과를 판단하는 프로세스가 어느 정도 정립된 상황이었습니다. 마케터는 두 가지 방식으로 LTV 예측값을 제공받았는데, 하나는 대시보드, 하나는 jupyter notebook 형태의 코드였습니다.

LTV 예측 모델은 BTYD (Buy Till You Die) 확률 모델 기반으로 MCMC 시뮬레이션을 수행하는 방식이었고, 한 코호트의 7일 간 평균 데이터를 바탕으로, 365일 간의 평균 LTV를 예측하는 형태였습니다.

프로젝트에 대한 자세한 내용은 [여기 프로젝트 문서](./proj_ltv_stg_1.md)에, LTV 모델링 및 MCMC를 활용한 예측 방식에 대해서는 [별도의 모델링 설명 문서](./ltv_modeling_mcmc.md)에 정리했습니다.

### Stage 2: LTV 모델 성능 개선

Stage 1에서의 LTV 모델은 특정 한 게임의 유저 패턴을 바탕으로 얻은 인사이트가 반영됐다보니, 다른 게임에 적용했을 때 오차가 있을 것으로 예상했습니다. 하지만, 예측하려는 타겟 기간 자체가 365일로 길었기 때문에 새로운 게임에 대한 LTV 모델 개선을 빠르게 진행하는 것은 어려웠습니다. 일종의 콜드 스타트 문제라고도 볼 수 있겠습니다.

아무 증거없이 모델 개선을 실행하는 것보다는, 새로운 게임에 적용한지 365일 이후부터 LTV의 실제값과 예측값의 오차를 추적해보기로 결정했습니다. Stage 2는 바로 이 시점부터 시작된 프로젝트였습니다.

[모델링 문서](./ltv_modeling_mcmc.md)에서 언급했듯이, LTV 모델의 큰 구성인 ARPU(Average Revenue Per User) 예측과 Life Time 예측 중 ARPU 예측에 휴리스틱 기반의 가정들이 많았습니다. Life Time에도 많은 가정이 들어가지만 일반적인 모바일 게임 리텐션 패턴에서 크게 벗어나지 않는다고 보았습니다. 때문에 실제 오차를 확인해본 뒤, 예상대로 ARPU 쪽의 예측의 오차 비중이 클 경우 전체적인 뼈대를 유지하되 ARPU 예측에 추가적인 fitting 모델이 들어가는 편이 효율적일 것이라 판단했습니다.

실제 오차를 확인해본 결과, 예상대로 ARPU 예측의 오차가 비중이 높았습니다. 데이터 분석 결과 7일 간의 ARPU 데이터와 365일의 ARPU에서 강한 선형성을 볼 수 있었기 떄문에 이를 단순한 linear regression으로 fitting 했습니다.

Linear regression 적용 이후에도 지속적으로 LTV 예측 오차를 추적했고, 만족할만한 오차 개선을 확인할 수 있었습니다.

### Stage 3: LTV 웹앱 개발

제가 생각한 데이터 사이언티스트의 역할은 그저 예측값을 정확하게 제공하는 것에 그치지 않았습니다. 결국은 의사결정 과정에서 얼마나 실질적으로 도움이 되는지, 더 효율적인 방법으로 도움을 줄 수 있는지 고민하는 것이 더 근본적인 역할이라고 생각했습니다. Stage 1, 2를 거치면서 모델의 예측력 측면에서는 개선이 있었으나, 사용성 측면, 그리고 유지보수 측면에서는 아직 많은 불편함이 있었습니다. 마케터와의 인터뷰를 통해 사용성 측면의 불편함을 파악하고, 제가 개발 과정에서 느낀 유지보수 측면에서의 개선점을 정리하여 LTV 웹앱 개발 프로젝트를 진행했습니다.

사용성 측면에서 대부분의 문제는, 마케터가 익숙하지 않은 서버에 접속해서 jupyter notebook을 업로드하고 실행해야 하는 환경에서 비롯됐습니다. LTV 예측이 실행되는 동안 웹브라우저 세션을 종료하지 않고 유지해야 했는데, 그동안 렌더링이나 데이터로 인한 메모리 점유 때문에 브라우저 리소스를 많이 소모해서 다른 업무에 지장이 가기도 했습니다. 그래서 시간이 오래 걸릴만한 LTV 예측 작업을 별도의 백엔드 서버에서 비동기로 처리하고, 그 결과만 웹을 통해 확인할 수 있도록 웹 애플리케이션을 개발하는 방향으로 기획했습니다. 그러지 않아도 당시 빅데이터 및 BI가 데이터 업계의 큰 화두로 떠오르면서 streamlit, dash 등 웹 기술을 잘 모르는 데이터 사이언티스트도 쉽게 웹앱을 만들 수 있는 라이브러리가 유행하던 시기였습니다. 팀 내의 데이터 분석가 및 데이터 사이언티스트들이 이미 plotly라는 라이브러리를 활용하여 인터랙티브한 시각화를 많이 제공하고 있었기 때문에, 사용자의 경험을 비슷하게 유지하기 위해 dash를 선택해 프론트엔드 쪽을 구현했습니다.

유지보수 및 성능 측면에서도 몇 가지 문제가 있었습니다. 우선 매번 LTV 예측 작업을 실행시킬 때마다 파라미터만 바뀌고 같은 로직의 데이터 전처리 과정이 반복됐는데 이 전처리 과정만 해도 전체 작업 시간의 절반 정도를 차지하고 있었습니다. 그래서 연산량이 큰 쿼리 작업들은 별도의 DW(Data Warehouse)에 매일 단위로 적재하고, LTV 예측 시에는 최소한의 전처리만 하도록 파이프라인을 구성했습니다. 또한 LTV 예측값이 매 실행 때마다 휘발되어 과거 분석 결과를 다시 재현하기 어려운 문제가 있었습니다. 이를 해결하기 위해 AWS lambda 및 Sagemaker Pipeline 기술 스택을 채용해, dash 프론트에서 발생한 요청이 생기면 lambda를 통해 Sagemaker pipeline job을 트리거하고, 그 결과를 S3에 적재한 뒤 다시 lambda를 통해 slack 알림을 보내는 플로우를 구현했습니다.

이를 통해 LTV 예측 실행이 마케터의 본업을 방해하지 않고 더 효율적으로 활용할 수 있었다는 피드백을 받을 수 있었습니다. 데이터 사이언스 팀 입장에서도 job 단위의 버전 관리 및 MCMC를 통해 예측한 결과를 저장해두고 계속 재활용할 수가 있었고 전체 작업 시간도 크게 단축시킬 수 있었습니다.

### Stage 4: 딥러닝 기반의 LTV 모델링

LTV 예측 서비스 자체는 마케팅 팀에서 꾸준히 활용하고 있었지만, 이를 2-3인 규모의 작은 데이터 사이언스 팀에서, 타 머신러닝 프로젝트까지 진행하면서 유지보수하는 데에 부담이 계속 쌓이고 있었습니다. 아무래도 MCMC 자체가 일반적인 머신러닝, 딥러닝에 비해 널리 쓰이는 기법은 아니다보니 방법론에 대한 학습 및 비즈니스 맥락을 타 팀원에게 전달하기가 어려웠습니다. 또한 특정 확률 분포를 고정해둔 모델이기 때문에 다른 문제에 적용할 수 있는 범용성이 떨어지고, 다양한 feature를 사용하기도 어렵고, output의 형태도 쉽게 변경하기 어려운 등 지속적으로 변경되는 요구사항에 비해 유연성이 부족하다는 문제도 있었습니다. 그래서 4년 넘게 잘 서비스 해오던 예측이지만 더 이상의 개선이 어렵다고 판단해 과감하게 근본적인 모델링 방식을 변경하게 되었습니다.

우선 태스크 정의를 변경했습니다. 기존에는 코호트 별 7일 간의 매출 평균과 리텐션 값들을 토대로, 365일 평균 LTV라는 스칼라 값을 뽑는 태스크였습니다. 하지만 Stage 2 과정에서도 느꼈듯이, 새로운 게임에 적용해서 빠르게 개선을 해보려면 더 빠른 피드백을 받을 수 있는 문제 세팅이 중요했습니다. 그래서 새로운 태스크는 일종의 seq-to-seq regression 태스크로 정의해, 0-7일차의 데이터 배열을 받아, 이후 1년 동안(8-364일차)의 LTV 예측값 배열을 뽑아내는 것으로 변경했습니다. 이렇게 하면 365일을 기다리지 않고도 30일, 60일 등 중간 시점에서 예측값과 실제값을 비교해 모델을 검증할 수 있습니다.

모델링 방식은 크게 2가지를 선택했습니다. 한정적인 인력 내에서 어떤 모델링 방식이 맞을지 최대한 탐색하고 비교분석하기 위해서 입니다. 하나는 베이스라인 모델, 하나는 메인 예측 모델의 역할로 고려했습니다. 베이스라인으로서 시도해본 것은 단순한 MLP(Multi-Layer Perceptron) 구조였습니다. 구현이 단순하기 때문에 다양한 feature를 넣어보고 빠르게 실험해보고 싶은 의도에 잘 맞을 것이라고 판단했습니다. 메인 모델로는 문헌 조사를 통해 TiDE(Time-series Dense Encoder)를 선택했습니다. 예측하려는 데이터가 시계열이다보니 시계열에 특화된 딥러닝 모델을 위주로 찾아봤고, 365일이라는 기간이 꽤나 장기 예측이기 때문에 이에 대한 강건성이 돋보이는 모델링이라는 점이 주요 선택 요인이었습니다.

하지만, 예측 결과가 LTV의 특성을 잘 반영하지 못하는 문제가 있었습니다. LTV는 시간이 갈수록 누적되는 값이어야 하는데, 그런 constraint를 반영하기 위해서는 데이터셋의 가공이 유연하게 이뤄져야 했습니다. 당시에는 모델 개발 과정에서 데이터 전처리의 유연성을 충분히 고려하지 못하고 이전 Stage처럼 스키마를 어느 정도 고정시켜놓고 빠르게 데이터를 추출하도록 파이프라인을 구축하는 데에 집중했는데, 이런 점이 오히려 모델 개발의 발목을 잡았던 것 같습니다. 또한, 캠페인 단위로 특성을 뽑아내다보니 데이터 수 자체가 충분히 많지 않았던 점도 있었습니다. 이 때문에 예측값의 오차를 분석해봤을 때 underfitting이 되는 패턴이 많이 보였습니다.

### Stage 5: LTV MLOps

(작성 중)
