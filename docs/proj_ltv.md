# 마케팅 Life Time Value (LTV) 예측 프로젝트

진행 기간: 2021.01 ~ 2024.03

## 프로젝트 소개

효율적인 마케팅 예산 집행을 위해 캠페인 별 평생 가치(LTV)를 예측하는 프로젝트.

## 문제 상황

- 마케팅은 '캠페인'이라는 단위로 예산을 집행함. 캠페인 별로 초반 3-7 일 동안의 퍼포먼스 데이터를 측정해, 장기적으로 **'가망이 있는'** 캠페인 위주로 예산을 빠르게 재집행함으로써 효율적으로 마케팅을 지속하는 것이 주 목표.
- 초반 퍼포먼스로만 캠페인을 판단하는 것은 마케터 개인의 경험과 주관에 의존할 수 밖에 없기 때문에 안정적인 지표가 필요함.
- 퍼포먼스 지표로 주로 활용하는 것은 광고 비용 대비 회수율(ROAS)이지만, 이 지표는 자연 유입된 유저를 대상으로 계산할 수 없음. LTV 값을 통해 ROAS를 계산하는 것도 가능하기 때문에 결국 LTV를 예측하는 것이 더 보편적으로 활용 가능.

## 프로젝트 목표

- 마케터가 캠페인의 장기 성과를 예측하는 데 도움이 되는 데이터를 제공한다. 이를 위해 초기 데이터를 활용해 광고 비용 대비 회수율(ROAS)이나 평생 가치(LTV)를 예측한다.

## 프로젝트 변천사

LTV 프로젝트는 제가 이어받기 전인 2017년부터 연구가 시작돼서 장장 7년이 넘게 지속된 프로젝트인만큼, 프로젝트 나름의 역사를 가지고 있습니다. 제가 프로젝트에 참여하기 시작한 2021년부터, 프로젝트가 마무리 된 2024년까지의 변천사를 큼직한 변화를 기준으로 '스테이지'로 구분해 설명해보겠습니다.

| stage | 기간 | 한 줄 요약 | 모델링 | 서빙 방식 | 데이터/훈련/서빙 파이프라인 |
| --- | --- | --- | --- | --- | --- |
| 1 | 2021 | 기존 서비스 유지보수 | Bayesian (MCMC) | dashboard / jupyter notebook | 서빙: airflow |
| 2 | 2022 | 모델 성능 개선 | MCMC + linear regression | dashboard / jupyter notebook | 서빙: airflow |
| 3 | 2023 상반기 | UX + 속도 개선 | 위와 동일 | AWS Sagemaker + Dash web | 데이터: AWS lambda, 서빙: AWS Sagemaker + lambda |
| 4 | 2023 하반기 | 모델링 방법론 변경 | Deep learning (MLP, TiDE) | dashboard | 데이터: databricks, 훈련: mlflow, 서빙: databricks |
| 5 | 2024 | 초기 수준의 MLOps 구축 | classical ML | mlflow model registry | 데이터: databricks, 훈련: mlflow, 서빙: mlflow |

### Stage 1: LTV 초기 모델

LTV 예측 프로젝트는 제가 입사한 2021년 이전부터 오랫동안 연구가 이어진 오래된 프로젝트로, 이미 LTV 예측값을 통해 마케터가 캠페인의 성과를 판단하는 프로세스가 어느 정도 정립된 상황이었습니다. 마케터는 두 가지 방식으로 LTV 예측값을 제공받았는데, 하나는 대시보드, 하나는 jupyter notebook 형태의 코드였습니다.

LTV 예측 모델은 BTYD (Buy Till You Die) 확률 모델 기반으로 MCMC 시뮬레이션을 수행하는 방식이었고, 한 코호트의 7일 간 평균 데이터를 바탕으로, 365일 간의 평균 LTV를 예측하는 형태였습니다.

프로젝트에 대한 자세한 내용은 [여기 프로젝트 문서](./proj_ltv_stg_1.md)에, LTV 모델링 및 MCMC를 활용한 예측 방식에 대해서는 [별도의 모델링 설명 문서](./ltv_modeling_mcmc.md)에 정리했습니다.

### Stage 2: LTV 모델 개선

Stage 1에서의 LTV 모델은 특정 한 게임의 유저 패턴을 바탕으로 얻은 인사이트가 반영됐다보니, 다른 게임에 적용했을 때 오차가 있을 것으로 예상했습니다. 하지만, 예측하려는 타겟 기간 자체가 365일로 길었기 때문에 새로운 게임에 대한 LTV 모델 개선을 빠르게 진행하는 것은 어려웠습니다. 일종의 콜드 스타트 문제라고도 볼 수 있겠습니다.

아무 증거없이 모델 개선을 실행하는 것보다는, 새로운 게임에 적용한지 365일 이후부터 LTV의 실제값과 예측값의 오차를 추적해보기로 결정했습니다. Stage 2는 바로 이 시점부터 시작된 프로젝트였습니다.

[모델링 문서](./ltv_modeling_mcmc.md)에서 언급했듯이, LTV 모델의 큰 구성인 ARPU(Average Revenue Per User) 예측과 Life Time 예측 중 ARPU 예측에 휴리스틱 기반의 가정들이 많았습니다. Life Time에도 많은 가정이 들어가지만 일반적인 모바일 게임 리텐션 패턴에서 크게 벗어나지 않는다고 보았습니다. 때문에 실제 오차를 확인해본 뒤, 예상대로 ARPU 쪽의 예측의 오차 비중이 클 경우 전체적인 뼈대를 유지하되 ARPU 예측에 추가적인 fitting 모델이 들어가는 편이 효율적일 것이라 판단했습니다.

실제 오차를 확인해본 결과, 예상대로 ARPU 예측의 오차가 비중이 높았습니다. 데이터 분석 결과 7일 간의 ARPU 데이터와 365일의 ARPU에서 강한 선형성을 볼 수 있었기 떄문에 이를 단순한 linear regression으로 fitting 했습니다.

Linear regression 적용 이후에도 지속적으로 LTV 예측 오차를 추적했고, 만족할만한 오차 개선을 확인할 수 있었습니다.

### Stage 3: LTV 웹앱 개발

(작성 중)

### Stage 4: 딥러닝 기반의 LTV 모델링

(작성 중)

### Stage 5: LTV MLOps

(작성 중)
